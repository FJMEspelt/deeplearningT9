# ğŸŒ„ Intel Image Classification â€“ Deep Learning Practice (T9)

This project is the final evaluation exercise for the Deep Learning module. It implements and compares multiple convolutional neural network (CNN) models for multi-class image classification on the **Intel Image Classification** dataset.

## ğŸ“ Dataset

The dataset comes from [Kaggle - Intel Image Classification](https://www.kaggle.com/datasets/puneet6060/intel-image-classification) and contains **6 classes** of natural scenes:

- 0: Buildings  
- 1: Forest  
- 2: Glacier  
- 3: Mountain  
- 4: Sea  
- 5: Street  

Each image is RGB and has shape **150Ã—150Ã—3**.

- `seg_train/` contains 14,000 labeled training images.
- `seg_test/` contains 3,000 labeled test images.
- `seg_pred/` contains 7,000 unlabeled images (not used in this project).

## ğŸ§  Models implemented

| Model ID                      | Script                         | Description                                              |
|-------------------------------|--------------------------------|----------------------------------------------------------|
| **1 â€“ Base CNN**              | `scripts/02_model_base.py`     | Simple convolutional network with 3 blocks and dense head. |
| **2 â€“ Deep CNN**              | `scripts/03_model_deep.py`     | Augmented CNN with extra conv blocks, batch norm & dropout. |
| **3 â€“ Hyperparameter Tuning** | `scripts/04_hyperparam_tuning.py` | RandomSearch over L1/L2, initializers, activations, dropout, LR. |
| **4 â€“ Transfer Learning**     | `scripts/05_transfer_learning.py` | Fine-tuning ResNet50 pretrained on ImageNet in two phases. |
| **5 â€“ Data Augmentation**     | `scripts/06_data_augmentation.py`| Retraining best model with ImageDataGenerator augmentations. |
| **6 â€“ Evaluation Plot**       | `scripts/07_evaluation.py`     | Compares `val_accuracy` curves for all models.           |
| **7 â€“ Evaluation Table**      | `scripts/08_evaluation_table.py`| Table of test accuracy for all saved models.             |

## ğŸ“‚ Folder structure

intel_image_classification/
â”‚
â”œâ”€â”€ src/                         â† Source code modules
â”‚   â”œâ”€â”€ config.py                â† Configuration constants (paths, hyperparams)
â”‚   â””â”€â”€ data_utils.py            â† Data generator utilities and preprocessing
|   â””â”€â”€ model_zoo.py   
â”œâ”€â”€ scripts/                      â† Python scripts for training and evaluation
â”‚   â”œâ”€â”€ 02_model_base.py
â”‚   â”œâ”€â”€ 03_model_deep.py
â”‚   â”œâ”€â”€ 04_hyperparam_tuning.py
â”‚   â”œâ”€â”€ 05_transfer_learning.py
â”‚   â”œâ”€â”€ 06_data_augmentation.py
â”‚   â”œâ”€â”€ 07_evaluation.py
â”‚   â””â”€â”€ 08_evaluation_table.py
|
â”œâ”€â”€ saved_models/                â† Trained models in .keras format
â”œâ”€â”€ histories/                   â† Training histories (metrics.json, plots)
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                  â† Final comparison plots & tables


## ğŸš€ How to run

1. **Install dependencies**:
   ```bash
   conda env create -f environment.yml
   conda activate dl
   ```
2. **Train or re-train models**:
   ```bash
   python -m scripts/02_model_base
   python -m scripts/03_model_deep
   python -m scripts/04_hyperparam_tuning
   python -m scripts/05_transfer_learning
   python -m scripts/06_data_augmentation
   ```
3. **Compare validation accuracy curves**:
   ```bash
   python -m scripts/07_evaluation
   ```
4. **Generate test accuracy table**:
   ```bash
   python -m scripts/08_evaluation_table
   ```
5. **Results**:
   - Models in `saved_models/`
   - Histories and plots in `histories/` and `reports/figures/`